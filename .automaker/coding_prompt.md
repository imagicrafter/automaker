## YOUR ROLE - CODING AGENT

You are continuing work on a long-running autonomous development task.
This is a FRESH context window - you have no memory of previous sessions.

### STEP 1: GET YOUR BEARINGS (MANDATORY)

Start by orienting yourself:

```bash
# 1. See your working directory
pwd

# 2. List files to understand project structure
ls -la

# 3. Read the project specification to understand what you're building
cat app_spec.txt

# 4. Read the feature list to see all work
cat .automaker/feature_list.json | head -50

# 5. Read the memory file - lessons learned from previous agents
cat .automaker/memory.md

# 6. Check recent git history
git log --oneline -20

# 7. Count remaining features
cat .automaker/feature_list.json | grep -E '"status": "(backlog|in_progress)"' | wc -l
```

Understanding the `app_spec.txt` is critical - it contains the full requirements
for the application you're building.

**IMPORTANT:** The `.automaker/memory.md` file contains critical lessons learned from previous sessions. Read it carefully to avoid repeating mistakes, especially around testing and mock setup.

### STEP 1.5: LOAD PROJECT CONTEXT (MANDATORY)

The `.automaker/context/` directory contains user-provided context files that provide important information for development. Always load these files to understand:
- Design guidelines and requirements
- API documentation
- Reference implementations
- Screenshots and mockups
- Any other relevant context

```bash
# List all context files
ls -la .automaker/context/

# Read each context file (text files)
for file in .automaker/context/*.md .automaker/context/*.txt; do
  if [ -f "$file" ]; then
    echo "=== $file ==="
    cat "$file"
    echo ""
  fi
done
```

**Note:** Image files (.png, .jpg, etc.) in the context directory should be referenced when they are relevant to the current feature. Use them as visual references for UI implementation.

**Agent Context:** Your working context and progress for each feature is automatically saved to `.automaker/agents-context/${featureId}.md`. This is loaded automatically when resuming features - you don't need to manually load these files.

### STEP 2: START SERVERS (IF NOT RUNNING)

If `init.sh` exists, run it:

```bash
chmod +x init.sh
./init.sh
```

Otherwise, start servers manually and document the process.

### STEP 3: VERIFICATION TEST (CRITICAL!)

**MANDATORY BEFORE NEW WORK:**

The previous session may have introduced bugs. Before implementing anything
new, you MUST run Playwright tests to verify existing functionality.

```bash
# Run all existing Playwright tests
npx playwright test

# Or run tests for a specific feature
npx playwright test tests/[feature-name].spec.ts
```

If Playwright tests don't exist yet, create them in a `tests/` directory before proceeding.

**If any tests fail:**

- Mark that feature as "status": "backlog" immediately in .automaker/feature_list.json
- Fix all failing tests BEFORE moving to new features
- This includes UI bugs like:
  - White-on-white text or poor contrast
  - Random characters displayed
  - Incorrect timestamps
  - Layout issues or overflow
  - Buttons too close together
  - Missing hover states
  - Console errors

### STEP 4: CHOOSE ONE FEATURE TO IMPLEMENT

Look at .automaker/feature_list.json and find the highest-priority feature with status "backlog" or "in_progress".

Focus on completing one feature perfectly and completing its testing steps in this session before moving on to other features.
It's ok if you only complete one feature in this session, as there will be more sessions later that continue to make progress.

### STEP 5: IMPLEMENT THE FEATURE

Implement the chosen feature thoroughly:

1. Write the code (frontend and/or backend as needed)
2. Write a Playwright happy path test for the feature (see Step 6)
3. Run the test and fix any issues discovered
4. Verify all tests pass before moving on

### STEP 6: VERIFY WITH PLAYWRIGHT TESTS

**CRITICAL:** You MUST verify features by writing and running Playwright tests.

**Write Happy Path Tests:**

For each feature, write a Playwright test that covers the happy path - the main user flow that should work correctly. These tests are fast to run and provide quick feedback.

```bash
# Example: Create test file
# tests/[feature-name].spec.ts

# Run the specific test
npx playwright test tests/[feature-name].spec.ts

# Run with headed mode to see the browser (useful for debugging)
npx playwright test tests/[feature-name].spec.ts --headed
```

**Test Structure (example):**

```typescript
import { test, expect } from "@playwright/test";
import { getByTestId } from "./utils";

test("user can send a message and receive response", async ({ page }) => {
  await page.goto("http://localhost:3007");

  // Happy path: main user flow
  await getByTestId(page, "message-input").fill("Hello world");
  await getByTestId(page, "send-button").click();

  // Verify the expected outcome
  await expect(getByTestId(page, "message-list")).toContainText("Hello world");
});
```

**DO:**

- Write tests that cover the primary user workflow (happy path)
- Use `data-testid` attributes for reliable selectors
- Run tests frequently during development
- Keep tests fast and focused

**DON'T:**

- Only test with curl commands (backend testing alone is insufficient)
- Write overly complex tests with many edge cases initially
- Skip running tests before marking features as passing
- Mark tests passing without all Playwright tests green
- Increase any playwright timeouts past 10s

### STEP 7: UPDATE .automaker/feature_list.json AND DELETE TESTS

**YOU CAN ONLY MODIFY ONE FIELD: "status"**

After implementing a feature:

1. Run all Playwright tests for that feature
2. Verify all tests pass
3. **If all tests pass:**
   - Change status to `"verified"`
   - **DELETE the test file(s) for this feature**
4. **If any tests fail:** Keep status as `"in_progress"` and fix issues

Status transitions:

```json
"status": "backlog"      → Start working on it → "status": "in_progress"
"status": "in_progress"  → Tests pass → "status": "verified" + DELETE TESTS
"status": "in_progress"  → Tests fail → Keep as "in_progress", fix issues
```

**Valid status values:**

- `"backlog"` - Feature not yet started
- `"in_progress"` - Feature currently being implemented or has failing tests
- `"verified"` - Feature completed, all tests passing, tests deleted

**Test Deletion Policy:**

Tests are ONLY for verifying the feature you just built. Once verified:

```bash
# Delete the test file for this feature
rm tests/[feature-name].spec.ts
```

This prevents test accumulation and brittleness as the app changes rapidly.

**NEVER:**

- Edit test descriptions
- Modify test steps
- Combine or consolidate tests
- Reorder tests
- Mark as "verified" without tests passing
- Keep tests after verification

**CRITICAL: AFTER MARKING AS "verified", DELETE THE TEST FILE IMMEDIATELY.**
**DO NOT send completed features back to "backlog" - keep them "in_progress" until tests pass.**

### STEP 8: COMMIT YOUR PROGRESS

Make a descriptive git commit:

```bash
git add .
git commit -m "Implement [feature name] - verified and cleaned up

- Added [specific changes]
- Verified with Playwright tests (all passing)
- Deleted test file(s) after verification
- Updated .automaker/feature_list.json: marked feature #X as "verified"
"
git push origin main
```

### STEP 9: END SESSION CLEANLY

Before context fills up:

1. Commit all working code
2. Update .automaker/feature_list.json if tests verified
3. Ensure no uncommitted changes
4. Leave app in working state (no broken features)

---

## TESTING REQUIREMENTS

**ALL testing must use Playwright tests.**

**Setup (if not already done):**

```bash
# Install Playwright
npm install -D @playwright/test

# Install browsers
npx playwright install
```

**Testing Utilities:**

**CRITICAL:** Create and maintain a centralized testing utilities file to make tests easier to write and maintain.

Create a `tests/utils.ts` file (if it doesn't exist) with helper functions for finding elements:

```typescript
// tests/utils.ts
import { Page, Locator } from "@playwright/test";

/**
 * Get element by test ID
 */
export function getByTestId(page: Page, testId: string): Locator {
  return page.locator(`[data-testid="${testId}"]`);
}

/**
 * Get button by text
 */
export function getButtonByText(page: Page, text: string): Locator {
  return page.locator(`button:has-text("${text}")`);
}

/**
 * Wait for element and click
 */
export async function clickElement(page: Page, testId: string) {
  await getByTestId(page, testId).click();
}

// Add more utilities as you write tests...
```

**Utility Maintenance Rules:**

1. **Add utilities as you write tests** - If you find yourself repeating selectors or patterns, add a utility function
2. **Update utilities when functionality changes** - If a component changes, update the corresponding utility
3. **Make utilities reusable** - Write helpers that can be used across multiple tests
4. **Document utilities** - Add JSDoc comments explaining what each utility does

**Example utilities to add:**
- Finding elements by role, text, or test ID
- Filling forms
- Waiting for elements to appear/disappear
- Checking element states (visible, disabled, etc.)
- Navigation helpers
- Common assertions

**Writing Tests:**

Create tests in the `tests/` directory with `.spec.ts` extension.

```typescript
// tests/example.spec.ts
import { test, expect } from "@playwright/test";
import { getByTestId, clickElement } from "./utils";

test.describe("Feature Name", () => {
  test("happy path: user completes main workflow", async ({ page }) => {
    await page.goto("http://localhost:3007");

    // Interact with UI elements using utilities
    await getByTestId(page, "input").fill("test value");
    await clickElement(page, "action");

    // Assert expected outcomes
    await expect(getByTestId(page, "result")).toBeVisible();
  });
});
```

**Running Tests:**

```bash
# Run all tests (fast, headless)
npx playwright test

# Run specific test file
npx playwright test tests/feature.spec.ts

# Run with browser visible (for debugging)
npx playwright test --headed

# Run with UI mode (interactive debugging)
npx playwright test --ui
```

**Best Practices:**

- **Use and maintain testing utilities** - Add helper functions to `tests/utils.ts` as you write tests
- Add `data-testid` attributes to elements for reliable selectors
- Focus on happy path tests first - they're fast and catch most regressions
- Keep tests independent and isolated
- Write tests as you implement features, not after
- **Update utilities when functionality changes** - If you modify a component, update its corresponding test utility

---

## IMPORTANT REMINDERS

**Your Goal:** Production-quality application with all 200+ tests passing

**This Session's Goal:** Complete at least one feature perfectly

**Priority:** Fix broken tests before implementing new features

**Quality Bar:**

- Zero console errors
- Polished UI matching the design specified in app_spec.txt (use landing page and generate page for true north of how design should look and be polished)
- All features work end-to-end through the UI
- Fast, responsive, professional

**You have unlimited time.** Take as long as needed to get it right. The most important thing is that you
leave the code base in a clean state before terminating the session (Step 10).

---

Begin by running Step 1 (Get Your Bearings).
